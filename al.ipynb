{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0af8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import lxml\n",
    "from urllib.parse import urlparse,parse_qs,urlencode,urlunparse\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/117.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"zh-CN,zh;q=0.9,en;q=0.8\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-Site\": \"none\",\n",
    "    \"Sec-Fetch-User\": \"?1\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "    # 如果目标站点需要，可以加上 Cookie 或 Referer\n",
    "    # \"Referer\": \"https://example.com/\",\n",
    "    # \"Cookie\": \"name=value; name2=value2\"\n",
    "}\n",
    "\n",
    "def fetch_url(url,file=None):\n",
    "    respond=r.get(url,headers=headers)\n",
    "    if respond.status_code==200:\n",
    "        if file:\n",
    "            with open(file, \"w\") as f:\n",
    "                f.write(respond.text)\n",
    "            print(f\"File saved in {file}.\")\n",
    "        return respond\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download file. Status code: {respond.status_code}\")\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    url=\"https://wiki.biligame.com/blhx/首页\"\n",
    "    index_file=\"html/index.html\"\n",
    "    bg_index_file=\"html/bg.html\"   \n",
    "\n",
    "    if not os.path.exists(index_file):\n",
    "        fetch_url(url,index_file)\n",
    "    index_soup=bs(open(\"html/index.html\"),\"lxml\")\n",
    "    a_list=index_soup.find_all(\"a\",class_=\"menu-title-1\")\n",
    "    bg=[_ for _ in a_list if \"壁纸和插画\" in _.text][0]\n",
    "    parsed=urlparse(url)\n",
    "    bg_url=urlunparse(parsed._replace(path=bg[\"href\"]))\n",
    "\n",
    "    if not os.path.exists(bg_index_file):\n",
    "        fetch_url(bg_url,bg_index_file)\n",
    "    bg_soup=bs(open(bg_index_file),\"lxml\")\n",
    "\n",
    "    conn = sqlite3.connect('images.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS images\n",
    "                (Id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                URL TEXT,\n",
    "                title TEXT,\n",
    "                artist TEXT,\n",
    "                original_url TEXT)''')\n",
    "\n",
    "    current_shared_title = None\n",
    "\n",
    "    for li in bg_soup.select('li.gallerybox'):\n",
    "        thumb_div = li.select_one('div.thumb')\n",
    "        if thumb_div:\n",
    "            a_tag = thumb_div.find('a', class_='image')\n",
    "            if a_tag and 'href' in a_tag.attrs:\n",
    "                href = a_tag['href']\n",
    "            else:\n",
    "                href = None\n",
    "        else:\n",
    "            href = None\n",
    "        \n",
    "        # 处理gallerytext部分\n",
    "        gallerytext = li.select_one('div.gallerytext')\n",
    "        title = None\n",
    "        artist = None\n",
    "        \n",
    "        if gallerytext:\n",
    "            p_tag = gallerytext.find('p')\n",
    "            if p_tag:\n",
    "                if not p_tag.find('a'):\n",
    "                    title = p_tag.get_text(strip=True)\n",
    "                    current_shared_title = title  # 设置共享标题\n",
    "                else:\n",
    "                    artist = p_tag.get_text(strip=True)\n",
    "                    current_shared_title = None  # 重置共享标题\n",
    "            elif current_shared_title:\n",
    "                title = current_shared_title\n",
    "        \n",
    "        parsed=urlparse(url)\n",
    "        href=urlunparse(parsed._replace(path=href))\n",
    "        c.execute('''INSERT INTO images (URL, title, artist, original_url)\n",
    "                    VALUES (?, ?, ?, NULL)''', \n",
    "                    (href, title, artist))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "# 配置信息\n",
    "DATABASE_PATH = \"images.db\"  # SQLite数据库路径\n",
    "DOWNLOAD_DIR = \"downloads\"  # 下载根目录\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/117.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"zh-CN,zh;q=0.9,en;q=0.8\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-Site\": \"none\",\n",
    "    \"Sec-Fetch-User\": \"?1\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "    # 如果目标站点需要，可以加上 Cookie 或 Referer\n",
    "    # \"Referer\": \"https://example.com/\",\n",
    "    # \"Cookie\": \"name=value; name2=value2\"\n",
    "}\n",
    "REQUEST_DELAY = 1  # 请求延迟（秒），避免请求过快\n",
    "\n",
    "def ensure_directory_exists(path):\n",
    "    \"\"\"确保目录存在，不存在则创建\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"创建目录: {path}\")\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    \"\"\"下载文件并保存到指定路径\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, stream=True, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"下载失败: {url} - {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"清理文件名中的非法字符\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', '', name)\n",
    "\n",
    "def generate_unique_filename(artist, original_filename, existing_files):\n",
    "    \"\"\"生成唯一的文件名，避免重复\"\"\"\n",
    "    base_name = f\"{artist}_{original_filename}\"\n",
    "    if base_name not in existing_files:\n",
    "        return base_name\n",
    "    \n",
    "    # 如果文件名已存在，添加哈希后缀\n",
    "    name, ext = os.path.splitext(original_filename)\n",
    "    hash_suffix = hashlib.md5(artist.encode()).hexdigest()[:6]\n",
    "    return f\"{artist}_{name}_{hash_suffix}{ext}\"\n",
    "\n",
    "def process_database():\n",
    "    \"\"\"处理数据库中的记录，下载原始文件并更新数据库\"\"\"\n",
    "    # 连接数据库\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # 添加original_url列（如果不存在）\n",
    "    cursor.execute(\"PRAGMA table_info(images)\")\n",
    "    columns = [col[1] for col in cursor.fetchall()]\n",
    "    if \"original_url\" not in columns:\n",
    "        cursor.execute(\"ALTER TABLE images ADD COLUMN original_url TEXT\")\n",
    "        print(\"已添加original_url列\")\n",
    "    \n",
    "    # 获取需要处理的记录（original_url为空的记录）\n",
    "    cursor.execute(\"SELECT Id, URL, title, artist FROM images WHERE original_url IS NULL\")\n",
    "    records = cursor.fetchall()\n",
    "    \n",
    "    if not records:\n",
    "        print(\"没有需要处理的记录\")\n",
    "        return\n",
    "    \n",
    "    total_records = len(records)\n",
    "    print(f\"找到 {total_records} 条需要处理的记录\")\n",
    "    \n",
    "    # 创建下载根目录\n",
    "    ensure_directory_exists(DOWNLOAD_DIR)\n",
    "    \n",
    "    # 创建文件夹\"0\"（用于存放没有标题但有艺术家的文件）\n",
    "    folder_0 = os.path.join(DOWNLOAD_DIR, \"0\")\n",
    "    ensure_directory_exists(folder_0)\n",
    "    \n",
    "    # 获取文件夹\"0\"中已有的文件列表（用于避免文件名冲突）\n",
    "    existing_files = set()\n",
    "    if os.path.exists(folder_0):\n",
    "        existing_files = set(os.listdir(folder_0))\n",
    "    \n",
    "    # 处理每条记录\n",
    "    for i, record in enumerate(records, 1):\n",
    "        id_, url, title, artist = record\n",
    "        \n",
    "        print(f\"\\n处理记录 {i}/{total_records} (ID: {id_}): {url}\")\n",
    "        \n",
    "        try:\n",
    "            # 获取详情页内容\n",
    "            response = requests.get(url, headers=HEADERS, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # 解析HTML\n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "            \n",
    "            # 查找原始文件链接\n",
    "            full_media_div = soup.find('div', class_='fullMedia')\n",
    "            if not full_media_div:\n",
    "                print(f\"未找到原始文件链接: {url}\")\n",
    "                continue\n",
    "                \n",
    "            original_link = full_media_div.find('a', class_='internal')\n",
    "            if not original_link or 'href' not in original_link.attrs:\n",
    "                print(f\"未找到原始文件链接: {url}\")\n",
    "                continue\n",
    "                \n",
    "            original_url = original_link['href']\n",
    "            print(f\"找到原始文件URL: {original_url}\")\n",
    "            \n",
    "            # 确定保存目录\n",
    "            if title:\n",
    "                folder_name = sanitize_filename(title.strip())\n",
    "                save_dir = os.path.join(DOWNLOAD_DIR, folder_name)\n",
    "                ensure_directory_exists(save_dir)\n",
    "                \n",
    "                # 从URL提取文件名\n",
    "                file_name = os.path.basename(original_url)\n",
    "                save_path = os.path.join(save_dir, file_name)\n",
    "            else:\n",
    "                # 没有标题的情况\n",
    "                save_dir = folder_0\n",
    "                \n",
    "                # 从URL提取原始文件名\n",
    "                original_filename = os.path.basename(original_url)\n",
    "                \n",
    "                # 如果有艺术家信息\n",
    "                if artist:\n",
    "                    artist_clean = sanitize_filename(artist.strip())\n",
    "                    \n",
    "                    # 生成唯一的文件名（避免重复）\n",
    "                    file_name = generate_unique_filename(artist_clean, original_filename, existing_files)\n",
    "                    \n",
    "                    # 添加到现有文件列表（避免后续重复）\n",
    "                    existing_files.add(file_name)\n",
    "                else:\n",
    "                    # 既没有标题也没有艺术家\n",
    "                    file_name = original_filename\n",
    "                \n",
    "                save_path = os.path.join(save_dir, file_name)\n",
    "            \n",
    "            # 检查文件是否已存在\n",
    "            if os.path.exists(save_path):\n",
    "                print(f\"文件已存在: {save_path}\")\n",
    "                # 更新数据库但不重新下载\n",
    "                cursor.execute(\n",
    "                    \"UPDATE images SET original_url = ? WHERE Id = ?\",\n",
    "                    (original_url, id_)\n",
    "                )\n",
    "                conn.commit()\n",
    "                print(f\"记录 {id_} 更新成功\")\n",
    "                continue\n",
    "            \n",
    "            # 下载文件\n",
    "            print(f\"下载文件到: {save_path}\")\n",
    "            if download_file(original_url, save_path):\n",
    "                # 更新数据库\n",
    "                cursor.execute(\n",
    "                    \"UPDATE images SET original_url = ? WHERE Id = ?\",\n",
    "                    (original_url, id_)\n",
    "                )\n",
    "                conn.commit()\n",
    "                print(f\"记录 {id_} 更新成功\")\n",
    "            else:\n",
    "                print(f\"记录 {id_} 下载失败\")\n",
    "                \n",
    "            # 请求延迟，避免过快请求\n",
    "            time.sleep(REQUEST_DELAY)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"处理记录 {id_} 时出错: {str(e)}\")\n",
    "    \n",
    "    # 关闭数据库连接\n",
    "    conn.close()\n",
    "    print(\"\\n处理完成\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_database()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
